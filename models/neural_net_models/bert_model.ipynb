{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objects as go\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"review_data_new.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "241004fd903d4b41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6b57614360f81718"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cleaned = df[[\"star_rating\",'review_text']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df117c3d45e55db6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cleaned.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66f5be6695d00003"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to map stars to sentiment\n",
    "def map_sentiment(stars_received):\n",
    "    if stars_received <= 3:\n",
    "        return 0\n",
    "    elif stars_received <= 4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "# Mapping stars to sentiment into three categories\n",
    "df_cleaned['sentiment'] = [ map_sentiment(x) for x in df_cleaned['star_rating']]\n",
    "print(\"Number of rows per star rating:\")\n",
    "print(df_cleaned['sentiment'].value_counts())\n",
    "\n",
    "# Plotting the sentiment distribution\n",
    "plt.figure()\n",
    "pd.value_counts(df_cleaned['sentiment']).plot.bar(title=\"Sentiment distribution in df\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"No. of rows in df\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fcc84a73f0658ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cleaned"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f35fc7d8cc9f548"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cleaned.rename(columns = {'review_text':'sentence'}, inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "961486bc98c7455c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentiment_counts = df_cleaned['sentiment'].value_counts()\n",
    " \n",
    "fig =px.bar(x= {0:'Negative',1:'Neutral',2:'Positive'},\n",
    "            y= sentiment_counts.values,\n",
    "            color=sentiment_counts.index,\n",
    "            color_discrete_sequence =  px.colors.qualitative.Dark24,\n",
    "            title='<b>Sentiments Counts')\n",
    " \n",
    "fig.update_layout(title='Sentiments Counts',\n",
    "                  xaxis_title='Sentiment',\n",
    "                  yaxis_title='Counts',\n",
    "                  template='plotly_dark')\n",
    " \n",
    "# Show the bar chart\n",
    "fig.show()\n",
    "pyo.plot(fig, filename = 'Sentiments Counts.html', auto_open = True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a196839774c7a0c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.dropna(subset=['sentence'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61dc14ebe7f2c516"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "\tsoup = BeautifulSoup(text, \"html.parser\")\n",
    "\ttext = re.sub(r'\\[[^]]*\\]', '', soup.get_text())\n",
    "\tpattern = r\"[^a-zA-Z0-9\\s,']\"\n",
    "\ttext = re.sub(pattern, '', text)\n",
    "\treturn text\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdfde87a36e7b823"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "type(df_cleaned.sentence[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "284053267c04238a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "df_cleaned['Cleaned_sentence'] = df_cleaned['sentence'].apply(text_cleaning).tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3354e1e9e0ee8e9c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cleaned.Cleaned_sentence"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9881cf62385ea67"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to generate word cloud\n",
    "def generate_wordcloud(text,Title):\n",
    "    all_text = \" \".join(text)\n",
    "    wordcloud = WordCloud(width=800, \n",
    "                          height=400,\n",
    "                          stopwords=set(STOPWORDS), \n",
    "                          background_color='black').generate(all_text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(Title)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "617d7f63946ab97c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "positive = df_cleaned[df_cleaned['sentiment']==2]['Cleaned_sentence'].tolist()\n",
    "generate_wordcloud(positive,'Positive Review')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5926502c47c596b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "neutral = df_cleaned[df_cleaned['sentiment']==1]['Cleaned_sentence'].tolist()\n",
    "generate_wordcloud(positive,'Neutral Review')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccfdbb106baeb3ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "negative = df_cleaned[df_cleaned['sentiment']==0]['Cleaned_sentence'].tolist()\n",
    "generate_wordcloud(positive,'Negative Review')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e94d354c9138f35e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_test_pre, y_train, y_test_pre = train_test_split(df_cleaned['Cleaned_sentence'], df_cleaned['sentiment'], test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81ecb0f9c79e00f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_val, x_test, y_val, y_test = train_test_split(x_test_pre,\n",
    "                                                    y_test_pre,\n",
    "                                                    test_size=0.5, \n",
    "                                                    stratify = y_test_pre)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "399e619d7ee06593"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Tokenize and encode the data using the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "287c4c1665535bb9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_length = df_cleaned['Cleaned_sentence'].apply(len).max()\n",
    "print(f\"The maximum length of strings in the column is: {max_length}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "739b37137786158"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_len= 120\n",
    "# Tokenize and encode the sentences\n",
    "X_train_encoded = tokenizer.batch_encode_plus(x_train.tolist(),\n",
    "\t\t\t\t\t\t\t\t\t\t\tpadding=True, \n",
    "\t\t\t\t\t\t\t\t\t\t\ttruncation=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\tmax_length = max_len,\n",
    "\t\t\t\t\t\t\t\t\t\t\treturn_tensors='tf')\n",
    "\n",
    "X_val_encoded = tokenizer.batch_encode_plus(x_val.tolist(), \n",
    "                                              padding=True, \n",
    "                                              truncation=True,\n",
    "                                              max_length = max_len,\n",
    "                                              return_tensors='tf')\n",
    "\n",
    "X_test_encoded = tokenizer.batch_encode_plus(x_test.tolist(), \n",
    "\t\t\t\t\t\t\t\t\t\t\tpadding=True, \n",
    "\t\t\t\t\t\t\t\t\t\t\ttruncation=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\tmax_length = max_len,\n",
    "\t\t\t\t\t\t\t\t\t\t\treturn_tensors='tf')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d6ee75606c3644a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train.values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c2f8a0ca1af4522"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Reviews = x_train.values\n",
    "Target = y_train.values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62ecd09d079dd621"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k = 0\n",
    "print('Training Comments -->>',Reviews[k])\n",
    "print('\\nInput Ids -->>\\n',X_train_encoded['input_ids'][k])\n",
    "print('\\nDecoded Ids -->>\\n',tokenizer.decode(X_train_encoded['input_ids'][k]))\n",
    "print('\\nAttention Mask -->>\\n',X_train_encoded['attention_mask'][k])\n",
    "print('\\nLabels -->>',Target[k])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bdc9d9759236763"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Intialize the model\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "965f16635cb8dfa5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compile the model with an appropriate optimizer, loss function, and metrics\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8884fc795435ce8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 5: Train the model\n",
    "history = model.fit(\n",
    "\t[X_train_encoded['input_ids'], X_train_encoded['token_type_ids'], X_train_encoded['attention_mask']],\n",
    "\tTarget,\n",
    "\tvalidation_data=(\n",
    "\t[X_val_encoded['input_ids'], X_val_encoded['token_type_ids'], X_val_encoded['attention_mask']],y_val),\n",
    "\tbatch_size=32,\n",
    "\tepochs=3\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c95df0d250f649c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "\t[X_test_encoded['input_ids'], X_test_encoded['token_type_ids'], X_test_encoded['attention_mask']],\n",
    "\ty_test\n",
    ")\n",
    "print(f'Test loss: {test_loss}, Test accuracy: {test_accuracy}')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba9b79213f02aea3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7f3dcce2af87d027"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "12e20852267bf338"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = ''\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained(path +'/Tokenizer')\n",
    "\n",
    "# Save model\n",
    "model.save_pretrained(path +'/Model')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31a2929884ebc09b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(path +'/Tokenizer')\n",
    "\n",
    "# Load model\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained(path +'/Model')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "970272af0ade0398"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = bert_model.predict(\n",
    "\t[X_test_encoded['input_ids'], X_test_encoded['token_type_ids'], X_test_encoded['attention_mask']])\n",
    "\n",
    "# pred is of type TFSequenceClassifierOutput\n",
    "logits = pred.logits\n",
    "\n",
    "# Use argmax along the appropriate axis to get the predicted labels\n",
    "pred_labels = tf.argmax(logits, axis=1)\n",
    "\n",
    "# Convert the predicted labels to a NumPy array\n",
    "pred_labels = pred_labels.numpy()\n",
    "\n",
    "label = {\n",
    "\t1: 'positive',\n",
    "\t0: 'Negative'\n",
    "}\n",
    "\n",
    "# Map the predicted labels to their corresponding strings using the label dictionary\n",
    "pred_labels = [label[i] for i in pred_labels]\n",
    "Actual = [label[i] for i in y_test]\n",
    "\n",
    "print('Predicted Label :', pred_labels[:10])\n",
    "print('Actual Label :', Actual[:10])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ecef72487032a7a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Classification Report: \\n\", classification_report(Actual, pred_labels))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b6840950803a91e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
