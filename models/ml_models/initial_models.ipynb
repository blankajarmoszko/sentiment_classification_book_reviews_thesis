{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5aa05f1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:44:13.281088Z",
     "start_time": "2024-04-04T19:44:13.267170Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Import necessary libraries\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ef75b051f52a0fe",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T19:44:13.826704Z",
     "start_time": "2024-04-04T19:44:13.821571Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, Dropout, Conv2D, MaxPooling2D, Flatten, Embedding, LSTM, GRU, RNN\n",
    "from keras.utils import to_categorical, set_random_seed, pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec069be2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:44:15.281152Z",
     "start_time": "2024-04-04T19:44:14.326328Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "\n",
    "# Read the data file into a Pandas DataFrame\n",
    "df = pd.read_csv('/Users/blankajarmoszko/PycharmProjects/thesis/data/df_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7645b39e",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-04-04T19:44:15.854897Z",
     "start_time": "2024-04-04T19:44:15.842075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             title reviewer_name num_reviews num_followers  star_rating  \\\n0  The Stolen Heir     Emily May       2,031          310k          4.0   \n1  The Stolen Heir       jessica       2,563         42.2k          4.0   \n2  The Stolen Heir         katia         306           526          3.0   \n3  The Stolen Heir     madeline          111            18          3.0   \n4  The Stolen Heir    Haley pham          81          143k          4.0   \n\n                                         review_text num_likes  num_comments  \\\n0  Not quite The Cruel Prince but I enjoyed this ...     1,206           3.0   \n1  hmm. i didnt obsess over this one like i did w...       654           0.0   \n2  3.5 ★oak was a disappointment, but suren!! i l...     1,233           0.0   \n3  Every single mention of Oak’s hooves was a jum...     1,707           4.0   \n4  4.5 stars  star  fairy_light_skin_tone  face_h...     1,432           0.0   \n\n   sentiment                                       cleaned_text  \n0          1  quit,cruel,princ,enjoy,loti,love,back,world,lo...  \n1          1  hmm,didnt,obsess,one,like,origin,trilogywhil,e...  \n2          0  oak,disappoint,suren,love,much,cant,pretend,do...  \n3          0              everi,singl,mention,oak,hoov,jumpscar  \n4          1  star,star,fairy_light_skin_ton,face_holding_ba...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>reviewer_name</th>\n      <th>num_reviews</th>\n      <th>num_followers</th>\n      <th>star_rating</th>\n      <th>review_text</th>\n      <th>num_likes</th>\n      <th>num_comments</th>\n      <th>sentiment</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The Stolen Heir</td>\n      <td>Emily May</td>\n      <td>2,031</td>\n      <td>310k</td>\n      <td>4.0</td>\n      <td>Not quite The Cruel Prince but I enjoyed this ...</td>\n      <td>1,206</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>quit,cruel,princ,enjoy,loti,love,back,world,lo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Stolen Heir</td>\n      <td>jessica</td>\n      <td>2,563</td>\n      <td>42.2k</td>\n      <td>4.0</td>\n      <td>hmm. i didnt obsess over this one like i did w...</td>\n      <td>654</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>hmm,didnt,obsess,one,like,origin,trilogywhil,e...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Stolen Heir</td>\n      <td>katia</td>\n      <td>306</td>\n      <td>526</td>\n      <td>3.0</td>\n      <td>3.5 ★oak was a disappointment, but suren!! i l...</td>\n      <td>1,233</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>oak,disappoint,suren,love,much,cant,pretend,do...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The Stolen Heir</td>\n      <td>madeline</td>\n      <td>111</td>\n      <td>18</td>\n      <td>3.0</td>\n      <td>Every single mention of Oak’s hooves was a jum...</td>\n      <td>1,707</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>everi,singl,mention,oak,hoov,jumpscar</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Stolen Heir</td>\n      <td>Haley pham</td>\n      <td>81</td>\n      <td>143k</td>\n      <td>4.0</td>\n      <td>4.5 stars  star  fairy_light_skin_tone  face_h...</td>\n      <td>1,432</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>star,star,fairy_light_skin_ton,face_holding_ba...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82e706d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:44:17.105050Z",
     "start_time": "2024-04-04T19:44:17.042661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows per star rating:\n",
      "sentiment\n",
      "2    17996\n",
      "1    14874\n",
      "0    13876\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/n0_9mny57ys5rqmlmylz_2880000gn/T/ipykernel_7415/3462290488.py:16: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  pd.value_counts(df['sentiment']).plot.bar(title=\"Sentiment distribution in df\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to map stars to sentiment\n",
    "def map_sentiment(stars_received):\n",
    "    if stars_received <= 3:\n",
    "        return 0\n",
    "    elif stars_received <= 4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "# Mapping stars to sentiment into three categories\n",
    "df['sentiment'] = [ map_sentiment(x) for x in df['star_rating']]\n",
    "print(\"Number of rows per star rating:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "\n",
    "# Plotting the sentiment distribution\n",
    "plt.figure()\n",
    "pd.value_counts(df['sentiment']).plot.bar(title=\"Sentiment distribution in df\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"No. of rows in df\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f123973c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:44:17.369654Z",
     "start_time": "2024-04-04T19:44:17.364458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             title reviewer_name num_reviews num_followers  star_rating  \\\n0  The Stolen Heir     Emily May       2,031          310k          4.0   \n1  The Stolen Heir       jessica       2,563         42.2k          4.0   \n2  The Stolen Heir         katia         306           526          3.0   \n3  The Stolen Heir     madeline          111            18          3.0   \n4  The Stolen Heir    Haley pham          81          143k          4.0   \n\n                                         review_text num_likes  num_comments  \\\n0  Not quite The Cruel Prince but I enjoyed this ...     1,206           3.0   \n1  hmm. i didnt obsess over this one like i did w...       654           0.0   \n2  3.5 ★oak was a disappointment, but suren!! i l...     1,233           0.0   \n3  Every single mention of Oak’s hooves was a jum...     1,707           4.0   \n4  4.5 stars  star  fairy_light_skin_tone  face_h...     1,432           0.0   \n\n   sentiment                                       cleaned_text  \n0          1  quit,cruel,princ,enjoy,loti,love,back,world,lo...  \n1          1  hmm,didnt,obsess,one,like,origin,trilogywhil,e...  \n2          0  oak,disappoint,suren,love,much,cant,pretend,do...  \n3          0              everi,singl,mention,oak,hoov,jumpscar  \n4          1  star,star,fairy_light_skin_ton,face_holding_ba...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>reviewer_name</th>\n      <th>num_reviews</th>\n      <th>num_followers</th>\n      <th>star_rating</th>\n      <th>review_text</th>\n      <th>num_likes</th>\n      <th>num_comments</th>\n      <th>sentiment</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The Stolen Heir</td>\n      <td>Emily May</td>\n      <td>2,031</td>\n      <td>310k</td>\n      <td>4.0</td>\n      <td>Not quite The Cruel Prince but I enjoyed this ...</td>\n      <td>1,206</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>quit,cruel,princ,enjoy,loti,love,back,world,lo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Stolen Heir</td>\n      <td>jessica</td>\n      <td>2,563</td>\n      <td>42.2k</td>\n      <td>4.0</td>\n      <td>hmm. i didnt obsess over this one like i did w...</td>\n      <td>654</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>hmm,didnt,obsess,one,like,origin,trilogywhil,e...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Stolen Heir</td>\n      <td>katia</td>\n      <td>306</td>\n      <td>526</td>\n      <td>3.0</td>\n      <td>3.5 ★oak was a disappointment, but suren!! i l...</td>\n      <td>1,233</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>oak,disappoint,suren,love,much,cant,pretend,do...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The Stolen Heir</td>\n      <td>madeline</td>\n      <td>111</td>\n      <td>18</td>\n      <td>3.0</td>\n      <td>Every single mention of Oak’s hooves was a jum...</td>\n      <td>1,707</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>everi,singl,mention,oak,hoov,jumpscar</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Stolen Heir</td>\n      <td>Haley pham</td>\n      <td>81</td>\n      <td>143k</td>\n      <td>4.0</td>\n      <td>4.5 stars  star  fairy_light_skin_tone  face_h...</td>\n      <td>1,432</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>star,star,fairy_light_skin_ton,face_holding_ba...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d95efa53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:44:18.336685Z",
     "start_time": "2024-04-04T19:44:18.328443Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in the 'cleaned_text' column\n",
    "df = df.dropna(subset=['cleaned_text'])\n",
    "\n",
    "# Reset index after removing rows\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0b77344b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:44:18.738629Z",
     "start_time": "2024-04-04T19:44:18.721713Z"
    }
   },
   "outputs": [],
   "source": [
    "# def convert_to_list(text):\n",
    "#     return text.split(',')\n",
    "# df[\"cleaned_text\"] = df[\"cleaned_text\"].apply(convert_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ab730d9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:44:19.781942Z",
     "start_time": "2024-04-04T19:44:19.769315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             title reviewer_name num_reviews num_followers  star_rating  \\\n0  The Stolen Heir     Emily May       2,031          310k          4.0   \n1  The Stolen Heir       jessica       2,563         42.2k          4.0   \n2  The Stolen Heir         katia         306           526          3.0   \n3  The Stolen Heir     madeline          111            18          3.0   \n4  The Stolen Heir    Haley pham          81          143k          4.0   \n\n                                         review_text num_likes  num_comments  \\\n0  Not quite The Cruel Prince but I enjoyed this ...     1,206           3.0   \n1  hmm. i didnt obsess over this one like i did w...       654           0.0   \n2  3.5 ★oak was a disappointment, but suren!! i l...     1,233           0.0   \n3  Every single mention of Oak’s hooves was a jum...     1,707           4.0   \n4  4.5 stars  star  fairy_light_skin_tone  face_h...     1,432           0.0   \n\n   sentiment                                       cleaned_text  \n0          1  quit,cruel,princ,enjoy,loti,love,back,world,lo...  \n1          1  hmm,didnt,obsess,one,like,origin,trilogywhil,e...  \n2          0  oak,disappoint,suren,love,much,cant,pretend,do...  \n3          0              everi,singl,mention,oak,hoov,jumpscar  \n4          1  star,star,fairy_light_skin_ton,face_holding_ba...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>reviewer_name</th>\n      <th>num_reviews</th>\n      <th>num_followers</th>\n      <th>star_rating</th>\n      <th>review_text</th>\n      <th>num_likes</th>\n      <th>num_comments</th>\n      <th>sentiment</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The Stolen Heir</td>\n      <td>Emily May</td>\n      <td>2,031</td>\n      <td>310k</td>\n      <td>4.0</td>\n      <td>Not quite The Cruel Prince but I enjoyed this ...</td>\n      <td>1,206</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>quit,cruel,princ,enjoy,loti,love,back,world,lo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Stolen Heir</td>\n      <td>jessica</td>\n      <td>2,563</td>\n      <td>42.2k</td>\n      <td>4.0</td>\n      <td>hmm. i didnt obsess over this one like i did w...</td>\n      <td>654</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>hmm,didnt,obsess,one,like,origin,trilogywhil,e...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Stolen Heir</td>\n      <td>katia</td>\n      <td>306</td>\n      <td>526</td>\n      <td>3.0</td>\n      <td>3.5 ★oak was a disappointment, but suren!! i l...</td>\n      <td>1,233</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>oak,disappoint,suren,love,much,cant,pretend,do...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The Stolen Heir</td>\n      <td>madeline</td>\n      <td>111</td>\n      <td>18</td>\n      <td>3.0</td>\n      <td>Every single mention of Oak’s hooves was a jum...</td>\n      <td>1,707</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>everi,singl,mention,oak,hoov,jumpscar</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Stolen Heir</td>\n      <td>Haley pham</td>\n      <td>81</td>\n      <td>143k</td>\n      <td>4.0</td>\n      <td>4.5 stars  star  fairy_light_skin_tone  face_h...</td>\n      <td>1,432</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>star,star,fairy_light_skin_ton,face_holding_ba...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "705de8d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:44:20.029637Z",
     "start_time": "2024-04-04T19:44:20.026089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(df['cleaned_text'], df['sentiment'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "             title reviewer_name num_reviews num_followers  star_rating  \\\n0  The Stolen Heir     Emily May       2,031          310k          4.0   \n1  The Stolen Heir       jessica       2,563         42.2k          4.0   \n2  The Stolen Heir         katia         306           526          3.0   \n3  The Stolen Heir     madeline          111            18          3.0   \n4  The Stolen Heir    Haley pham          81          143k          4.0   \n\n                                         review_text num_likes  num_comments  \\\n0  Not quite The Cruel Prince but I enjoyed this ...     1,206           3.0   \n1  hmm. i didnt obsess over this one like i did w...       654           0.0   \n2  3.5 ★oak was a disappointment, but suren!! i l...     1,233           0.0   \n3  Every single mention of Oak’s hooves was a jum...     1,707           4.0   \n4  4.5 stars  star  fairy_light_skin_tone  face_h...     1,432           0.0   \n\n   sentiment                                       cleaned_text  \n0          1  quit,cruel,princ,enjoy,loti,love,back,world,lo...  \n1          1  hmm,didnt,obsess,one,like,origin,trilogywhil,e...  \n2          0  oak,disappoint,suren,love,much,cant,pretend,do...  \n3          0              everi,singl,mention,oak,hoov,jumpscar  \n4          1  star,star,fairy_light_skin_ton,face_holding_ba...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>reviewer_name</th>\n      <th>num_reviews</th>\n      <th>num_followers</th>\n      <th>star_rating</th>\n      <th>review_text</th>\n      <th>num_likes</th>\n      <th>num_comments</th>\n      <th>sentiment</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The Stolen Heir</td>\n      <td>Emily May</td>\n      <td>2,031</td>\n      <td>310k</td>\n      <td>4.0</td>\n      <td>Not quite The Cruel Prince but I enjoyed this ...</td>\n      <td>1,206</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>quit,cruel,princ,enjoy,loti,love,back,world,lo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Stolen Heir</td>\n      <td>jessica</td>\n      <td>2,563</td>\n      <td>42.2k</td>\n      <td>4.0</td>\n      <td>hmm. i didnt obsess over this one like i did w...</td>\n      <td>654</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>hmm,didnt,obsess,one,like,origin,trilogywhil,e...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Stolen Heir</td>\n      <td>katia</td>\n      <td>306</td>\n      <td>526</td>\n      <td>3.0</td>\n      <td>3.5 ★oak was a disappointment, but suren!! i l...</td>\n      <td>1,233</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>oak,disappoint,suren,love,much,cant,pretend,do...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The Stolen Heir</td>\n      <td>madeline</td>\n      <td>111</td>\n      <td>18</td>\n      <td>3.0</td>\n      <td>Every single mention of Oak’s hooves was a jum...</td>\n      <td>1,707</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>everi,singl,mention,oak,hoov,jumpscar</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Stolen Heir</td>\n      <td>Haley pham</td>\n      <td>81</td>\n      <td>143k</td>\n      <td>4.0</td>\n      <td>4.5 stars  star  fairy_light_skin_tone  face_h...</td>\n      <td>1,432</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>star,star,fairy_light_skin_ton,face_holding_ba...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T19:44:21.713577Z",
     "start_time": "2024-04-04T19:44:21.695755Z"
    }
   },
   "id": "cd6a37b288335836"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2144f26d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:44:24.366127Z",
     "start_time": "2024-04-04T19:44:21.949534Z"
    }
   },
   "outputs": [],
   "source": [
    "# bag of words\n",
    "\n",
    "# Vectorize the text using Bag-of-Words\n",
    "vectorizer_bow = CountVectorizer()\n",
    "X_train_vectorized_bow = vectorizer_bow.fit_transform(train_data)\n",
    "X_test_vectorized_bow = vectorizer_bow.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "str"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T19:44:24.369021Z",
     "start_time": "2024-04-04T19:44:24.364176Z"
    }
   },
   "id": "4c4ba7022124c569"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "853a413b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:44:26.744511Z",
     "start_time": "2024-04-04T19:44:24.440613Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vectorize the text using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(train_data)\n",
    "X_test_tfidf = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3f0f62",
   "metadata": {},
   "source": [
    "## Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c35f410",
   "metadata": {},
   "source": [
    "### Naive Bayes w/ BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e651b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "naive_bayes_model_bow = MultinomialNB()\n",
    "naive_bayes_model_bow.fit(X_train_vectorized_bow, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions_bow = naive_bayes_model_bow.predict(X_test_vectorized_bow)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, predictions_bow)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_report(test_labels, predictions_bow))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4dd492",
   "metadata": {},
   "source": [
    "### Naive Bayes with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d26a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train a Naive Bayes classifier\n",
    "naive_bayes_model_tf = MultinomialNB()\n",
    "naive_bayes_model_tf.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = naive_bayes_model_tf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_report(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM w/ tfidf"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78751df791c4c530"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X_train_tfidf,train_labels)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(X_test_tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, test_labels)*100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0fdd69d32b03d66"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obtain the confusion matrix\n",
    "cm = confusion_matrix(test_labels, predictions_SVM)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix - SVM Classifier\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f70e30108e79074"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9a06196a861d282a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_predictions_SVM = SVM.predict(X_train_tfidf)\n",
    "print(\"TRAIN SVM Accuracy Score -> \",accuracy_score(train_predictions_SVM, train_labels)*100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "671c38c0bc2d6a9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM with random search hyperparam tunning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c5fd43eed7d53be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Define the parameter distributions\n",
    "param_distributions = {\n",
    "    'C': uniform(loc=0.1, scale=100),  # Regularization parameter\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  # Kernel type\n",
    "    'degree': [2, 3, 4],  # Degree of the polynomial kernel (if polynomial)\n",
    "    'gamma': ['scale', 'auto']  # Kernel coefficient (for 'rbf', 'poly', and 'sigmoid')\n",
    "}\n",
    "\n",
    "# Create the SVM classifier\n",
    "svm_classifier = svm.SVC()\n",
    "\n",
    "# Perform randomized search with cross-validation\n",
    "random_search = RandomizedSearchCV(svm_classifier, param_distributions, n_iter=20, cv=5, scoring='accuracy', random_state=42)\n",
    "random_search.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Make predictions using the best model\n",
    "best_model = random_search.best_estimator_\n",
    "predictions = best_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(\"Accuracy Score:\", accuracy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "63f8b44bd0fa6492"
  },
  {
   "cell_type": "markdown",
   "id": "5f812581",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eda50c",
   "metadata": {},
   "source": [
    "### Logistic Regression w/ BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d335bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression classifier\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train_vectorized_bow, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = logistic_regression_model.predict(X_test_vectorized_bow)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_report(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52630ed",
   "metadata": {},
   "source": [
    "### Logistic Regression w/ tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a650a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression classifier\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = logistic_regression_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_report(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tunning Logistic Regression with TFIDF "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "142a86761c78dcdb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the Logistic Regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'penalty': ['l1', 'l2'],  # Penalty norm\n",
    "    'solver': ['liblinear', 'saga']  # Optimization algorithm\n",
    "}\n",
    "\n",
    "# Perform Grid Search cross-validation\n",
    "grid_search = GridSearchCV(estimator=logistic_regression_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_report(test_labels, predictions))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec05c6eef679eaeb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make predictions on the train and test set using the best model\n",
    "train_predictions = best_model.predict(X_train_tfidf)\n",
    "test_predictions = best_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate train and test accuracy\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "# Print train and test accuracy for the best model\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80307655076657db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "test_predictions = best_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c78e2afff87a28f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store misclassified instances\n",
    "misclassified_instances = []\n",
    "\n",
    "# Iterate over test instances\n",
    "for text, actual_label, predicted_label in zip(test_data, test_labels, test_predictions):\n",
    "    if actual_label != predicted_label:\n",
    "        # Append misclassified instance to the list\n",
    "        misclassified_instances.append({'Text': text, 'Actual Label': actual_label, 'Predicted Label': predicted_label})\n",
    "\n",
    "# Create a DataFrame from the list of misclassified instances\n",
    "misclassified_df = pd.DataFrame(misclassified_instances)\n",
    "\n",
    "# Print misclassified instances\n",
    "print(\"Misclassified Instances:\")\n",
    "misclassified_df.head()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eff4962b252a80fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of actual labels\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x='Actual Label', data=misclassified_df, palette='coolwarm', order=misclassified_df['Actual Label'].value_counts().index)\n",
    "plt.title('Distribution of Actual Labels')\n",
    "plt.xlabel('Actual Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Plot the distribution of predicted labels\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x='Predicted Label', data=misclassified_df, palette='coolwarm', order=misclassified_df['Predicted Label'].value_counts().index)\n",
    "plt.title('Distribution of Predicted Labels')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecee09069c8b5248"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df contains the \"cleaned_text\" and \"review_text\" columns\n",
    "# Assuming misclassified_df contains the \"Text\" column\n",
    "\n",
    "# Rename the \"Text\" column in misclassified_df to match the column name in df\n",
    "misclassified_df.rename(columns={'Text': 'cleaned_text'}, inplace=True)\n",
    "\n",
    "# Perform a merge based on the \"cleaned_text\" column\n",
    "merged_df = pd.merge(misclassified_df, df[['cleaned_text', 'review_text']], on='cleaned_text', how='left')\n",
    "\n",
    "# Print the merged DataFrame\n",
    "print(\"Merged DataFrame:\")\n",
    "merged_df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5301f069a26031f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df.review_text[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61552be3a99ec1f4"
  },
  {
   "cell_type": "markdown",
   "id": "4485fd92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T16:45:10.413079Z",
     "start_time": "2024-04-04T16:45:10.390723Z"
    }
   },
   "source": [
    "### Logistic Regression with TFIDF and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa8ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bde2f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate bigrams\n",
    "df['bigrams'] = df['cleaned_text'].apply(lambda x: list(ngrams(x, 2)))\n",
    "\n",
    "# Convert bigrams back to text\n",
    "df['bigrams_text'] = df['bigrams'].apply(lambda x: ' '.join([' '.join(gram) for gram in x]))\n",
    "\n",
    "# Use only bigrams for TF-IDF vectorization\n",
    "df['combined_text'] = df['bigrams_text']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['combined_text'], df['sentiment'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d92a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Train a model (e.g., logistic regression)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the train set\n",
    "train_predictions = model.predict(X_train_tfidf)\n",
    "\n",
    "# Evaluate the model on the train set\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print(\"Train Set:\")\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(classification_report(y_train, train_predictions))\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8f8d2d",
   "metadata": {},
   "source": [
    "### Logistic Regression with TFIDF and uni-bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ccd1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate uni-bigrams\n",
    "df['uni_bigrams'] = df['cleaned_text'].apply(lambda x: list(ngrams(x, 2)))\n",
    "\n",
    "# Convert uni-bigrams back to text\n",
    "df['uni_bigrams_text'] = df['uni_bigrams'].apply(lambda x: ' '.join([' '.join(gram) for gram in x]))\n",
    "\n",
    "# Combine unigrams and uni-bigrams for TF-IDF vectorization\n",
    "df['combined_text'] = df['cleaned_text'].apply(lambda x: ' '.join(x)) + ' ' + df['uni_bigrams_text']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['combined_text'], df['sentiment'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cb6c75da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:44:34.938781Z",
     "start_time": "2024-04-04T19:44:34.785500Z"
    }
   },
   "outputs": [],
   "source": [
    "# logistic regression cv\n",
    "# max iter = 2000\n",
    "# semi supervised learning\n",
    "# TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Train a model (e.g., logistic regression)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "de0a94a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:44:41.412985Z",
     "start_time": "2024-04-04T19:44:35.686528Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get feature names (unigrams and uni-bigrams)\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# Get coefficients assigned to each feature\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "# Combine feature names and coefficients into a dictionary\n",
    "feature_importance_dict = dict(zip(feature_names, coefficients))\n",
    "\n",
    "# Sort the dictionary by absolute coefficient values to see the most important features\n",
    "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Print or visualize the top features\n",
    "top_features = sorted_feature_importance[:20]  # Adjust the number of features to display\n",
    "for feature, importance in top_features:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4206ebe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:45:11.004560Z",
     "start_time": "2024-04-04T19:45:10.975250Z"
    }
   },
   "source": [
    "### TFIDF WITH TRIGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9d9597fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:45:16.602899Z",
     "start_time": "2024-04-04T19:45:14.355750Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[86], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# TF-IDF vectorization\u001B[39;00m\n\u001B[1;32m      2\u001B[0m tfidf_vectorizer \u001B[38;5;241m=\u001B[39m TfidfVectorizer()\n\u001B[0;32m----> 3\u001B[0m X_train_tfidf \u001B[38;5;241m=\u001B[39m \u001B[43mtfidf_vectorizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m X_test_tfidf \u001B[38;5;241m=\u001B[39m tfidf_vectorizer\u001B[38;5;241m.\u001B[39mtransform(X_test)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Train a model (e.g., logistic regression)\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2138\u001B[0m, in \u001B[0;36mTfidfVectorizer.fit_transform\u001B[0;34m(self, raw_documents, y)\u001B[0m\n\u001B[1;32m   2131\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_params()\n\u001B[1;32m   2132\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfidf \u001B[38;5;241m=\u001B[39m TfidfTransformer(\n\u001B[1;32m   2133\u001B[0m     norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm,\n\u001B[1;32m   2134\u001B[0m     use_idf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_idf,\n\u001B[1;32m   2135\u001B[0m     smooth_idf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msmooth_idf,\n\u001B[1;32m   2136\u001B[0m     sublinear_tf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msublinear_tf,\n\u001B[1;32m   2137\u001B[0m )\n\u001B[0;32m-> 2138\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_documents\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2139\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfidf\u001B[38;5;241m.\u001B[39mfit(X)\n\u001B[1;32m   2140\u001B[0m \u001B[38;5;66;03m# X is already a transformed view of raw_documents so\u001B[39;00m\n\u001B[1;32m   2141\u001B[0m \u001B[38;5;66;03m# we set copy to False\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1472\u001B[0m     )\n\u001B[1;32m   1473\u001B[0m ):\n\u001B[0;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1389\u001B[0m, in \u001B[0;36mCountVectorizer.fit_transform\u001B[0;34m(self, raw_documents, y)\u001B[0m\n\u001B[1;32m   1381\u001B[0m             warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   1382\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUpper case characters found in\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1383\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m vocabulary while \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlowercase\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1384\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m is True. These entries will not\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1385\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m be matched with any documents\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1386\u001B[0m             )\n\u001B[1;32m   1387\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m-> 1389\u001B[0m vocabulary, X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_count_vocab\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_documents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfixed_vocabulary_\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1391\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbinary:\n\u001B[1;32m   1392\u001B[0m     X\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mfill(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1295\u001B[0m, in \u001B[0;36mCountVectorizer._count_vocab\u001B[0;34m(self, raw_documents, fixed_vocab)\u001B[0m\n\u001B[1;32m   1293\u001B[0m     vocabulary \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(vocabulary)\n\u001B[1;32m   1294\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m vocabulary:\n\u001B[0;32m-> 1295\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1296\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1297\u001B[0m         )\n\u001B[1;32m   1299\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m indptr[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39miinfo(np\u001B[38;5;241m.\u001B[39mint32)\u001B[38;5;241m.\u001B[39mmax:  \u001B[38;5;66;03m# = 2**31 - 1\u001B[39;00m\n\u001B[1;32m   1300\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _IS_32BIT:\n",
      "\u001B[0;31mValueError\u001B[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'cleaned_text' is a column containing tokenized lists of strings\n",
    "\n",
    "# Convert trigrams back to text\n",
    "df['trigrams'] = df['cleaned_text'].apply(lambda x: list(ngrams(x, 3)))\n",
    "df['trigrams_text'] = df['trigrams'].apply(lambda x: ' '.join([' '.join(gram) for gram in x]))\n",
    "\n",
    "# Getting trigrams with CountVectorizer\n",
    "count_vectorizer = CountVectorizer(ngram_range=(3, 3))\n",
    "X1 = count_vectorizer.fit_transform(df['trigrams_text'])\n",
    "features_count = count_vectorizer.get_feature_names()\n",
    "\n",
    "print(\"\\n\\nCount Vectorizer Features : \\n\", features_count)\n",
    "print(\"\\n\\nX1 : \\n\", X1.toarray())\n",
    "\n",
    "# Applying TFIDF\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(3, 3))\n",
    "X2 = tfidf_vectorizer.fit_transform(df['trigrams_text'])\n",
    "features_tfidf = tfidf_vectorizer.get_feature_names()\n",
    "scores = X2.toarray()\n",
    "\n",
    "print(\"\\n\\nTFIDF Vectorizer Features : \\n\", features_tfidf)\n",
    "print(\"\\n\\nScores : \\n\", scores)\n",
    "\n",
    "# Getting top ranking features\n",
    "sums = X2.sum(axis=0)\n",
    "data1 = []\n",
    "for col, term in enumerate(features_tfidf):\n",
    "    data1.append((term, sums[0, col]))\n",
    "ranking = pd.DataFrame(data1, columns=['term', 'rank'])\n",
    "words = ranking.sort_values('rank', ascending=False)\n",
    "print(\"\\n\\nTop Ranking Words : \\n\", words.head(7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc189d9",
   "metadata": {},
   "source": [
    "### Word2Vec with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5ac28b96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:45:41.423174Z",
     "start_time": "2024-04-04T19:45:34.904603Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "#train_data, test_data, train_labels, test_labels = train_test_split(df['cleaned_text'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=train_data, vector_size=300, window=5, min_count=1, workers=4, sg=0)\n",
    "\n",
    "# Create average word vectors for each document\n",
    "def average_word_vectors(words, model, num_features):\n",
    "    feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "\n",
    "    for word in words:\n",
    "        if word in model.wv.index_to_key:\n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model.wv[word])\n",
    "\n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "# Create document vectors for the training set\n",
    "X_train = np.vstack([average_word_vectors(words, word2vec_model, 300) for words in train_data])\n",
    "\n",
    "# Create document vectors for the test set\n",
    "X_test = np.vstack([average_word_vectors(words, word2vec_model, 300) for words in test_data])\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression classifier\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train_scaled, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = logistic_regression_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_report(test_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e996b185",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:45:50.435642Z",
     "start_time": "2024-04-04T19:45:46.984847Z"
    }
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9f8ed268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:46:01.642756Z",
     "start_time": "2024-04-04T19:45:53.645955Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[90], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# logistic regression cv\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# max iter = 2000\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# semi supervised learning\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# TF-IDF vectorization\u001B[39;00m\n\u001B[1;32m      5\u001B[0m tfidf_vectorizer \u001B[38;5;241m=\u001B[39m TfidfVectorizer()\n\u001B[0;32m----> 6\u001B[0m X_train_tfidf \u001B[38;5;241m=\u001B[39m \u001B[43mtfidf_vectorizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m X_test_tfidf \u001B[38;5;241m=\u001B[39m tfidf_vectorizer\u001B[38;5;241m.\u001B[39mtransform(X_test)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Train a model (e.g., logistic regression)\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2138\u001B[0m, in \u001B[0;36mTfidfVectorizer.fit_transform\u001B[0;34m(self, raw_documents, y)\u001B[0m\n\u001B[1;32m   2131\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_params()\n\u001B[1;32m   2132\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfidf \u001B[38;5;241m=\u001B[39m TfidfTransformer(\n\u001B[1;32m   2133\u001B[0m     norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm,\n\u001B[1;32m   2134\u001B[0m     use_idf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_idf,\n\u001B[1;32m   2135\u001B[0m     smooth_idf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msmooth_idf,\n\u001B[1;32m   2136\u001B[0m     sublinear_tf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msublinear_tf,\n\u001B[1;32m   2137\u001B[0m )\n\u001B[0;32m-> 2138\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_documents\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2139\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfidf\u001B[38;5;241m.\u001B[39mfit(X)\n\u001B[1;32m   2140\u001B[0m \u001B[38;5;66;03m# X is already a transformed view of raw_documents so\u001B[39;00m\n\u001B[1;32m   2141\u001B[0m \u001B[38;5;66;03m# we set copy to False\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1472\u001B[0m     )\n\u001B[1;32m   1473\u001B[0m ):\n\u001B[0;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1389\u001B[0m, in \u001B[0;36mCountVectorizer.fit_transform\u001B[0;34m(self, raw_documents, y)\u001B[0m\n\u001B[1;32m   1381\u001B[0m             warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   1382\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUpper case characters found in\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1383\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m vocabulary while \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlowercase\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1384\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m is True. These entries will not\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1385\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m be matched with any documents\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1386\u001B[0m             )\n\u001B[1;32m   1387\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m-> 1389\u001B[0m vocabulary, X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_count_vocab\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_documents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfixed_vocabulary_\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1391\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbinary:\n\u001B[1;32m   1392\u001B[0m     X\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mfill(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1295\u001B[0m, in \u001B[0;36mCountVectorizer._count_vocab\u001B[0;34m(self, raw_documents, fixed_vocab)\u001B[0m\n\u001B[1;32m   1293\u001B[0m     vocabulary \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(vocabulary)\n\u001B[1;32m   1294\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m vocabulary:\n\u001B[0;32m-> 1295\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1296\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1297\u001B[0m         )\n\u001B[1;32m   1299\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m indptr[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39miinfo(np\u001B[38;5;241m.\u001B[39mint32)\u001B[38;5;241m.\u001B[39mmax:  \u001B[38;5;66;03m# = 2**31 - 1\u001B[39;00m\n\u001B[1;32m   1300\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _IS_32BIT:\n",
      "\u001B[0;31mValueError\u001B[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590f86f5",
   "metadata": {},
   "source": [
    "### Random Forrest with bofw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e42834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Random Forest model\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "random_forest_model.fit(X_train_vectorized_bow, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = random_forest_model.predict(X_test_vectorized_bow)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4069e7",
   "metadata": {},
   "source": [
    "### Random Forrest witb tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fed21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Random Forest model\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "random_forest_model.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = random_forest_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2776fda1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de377c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
