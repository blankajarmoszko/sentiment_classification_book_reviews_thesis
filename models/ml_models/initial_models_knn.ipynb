{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a86795f8057af19",
   "metadata": {},
   "source": [
    "# Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa05f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ad58e9dcfa92212"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec069be2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T04:02:51.746188Z",
     "start_time": "2024-04-17T04:02:50.751961Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the data file into a Pandas DataFrame\n",
    "df = pd.read_csv('/Users/blankajarmoszko/PycharmProjects/thesis/data/df_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645b39e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e706d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map stars to sentiment\n",
    "def map_sentiment(stars_received):\n",
    "    if stars_received <= 3:\n",
    "        return 0\n",
    "    elif stars_received <= 4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "# Mapping stars to sentiment into three categories\n",
    "df['sentiment'] = [ map_sentiment(x) for x in df['star_rating']]\n",
    "print(\"Number of rows per star rating:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "\n",
    "# Plotting the sentiment distribution\n",
    "plt.figure()\n",
    "pd.value_counts(df['sentiment']).plot.bar(title=\"Sentiment distribution in df\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"No. of rows in df\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f123973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95efa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in the 'cleaned_text' column\n",
    "df = df.dropna(subset=['cleaned_text'])\n",
    "\n",
    "# Reset index after removing rows\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705de8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(df['cleaned_text'], df['sentiment'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6a37b288335836",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2144f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words\n",
    "# Vectorize the text using Bag-of-Words\n",
    "vectorizer_bow = CountVectorizer()\n",
    "X_train_vectorized_bow = vectorizer_bow.fit_transform(train_data)\n",
    "X_test_vectorized_bow = vectorizer_bow.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853a413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(train_data)\n",
    "X_test_tfidf = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54842d575b11e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "        fit_prior=True, class_prior=None))),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'clf__estimator__alpha': (1e-1,1e-2, 1e-3)\n",
    "}\n",
    "\n",
    "grid_search_tune = GridSearchCV(pipeline, parameters, cv=2, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(train_data, train_labels)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_tune.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc43fdc41a35582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, ngram_range=(1,3))\n",
    "X_train_tfidf = vectorizer.fit_transform(train_data)\n",
    "X_test_tfidf = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ed2cc7a19347c5",
   "metadata": {},
   "source": [
    "### Bigrams and Uni-bigrams with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bde2f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, ngrams\n",
    "\n",
    "# necessary for this to work\n",
    "def convert_to_list(text):\n",
    "    return text.split(',')\n",
    "df[\"cleaned_text\"] = df[\"cleaned_text\"].apply(convert_to_list)\n",
    "\n",
    "# Generate bigrams\n",
    "df['bigrams'] = df['cleaned_text'].apply(lambda x: list(ngrams(x, 2)))\n",
    "\n",
    "# Convert bigrams back to text\n",
    "df['bigrams_text'] = df['bigrams'].apply(lambda x: ' '.join([' '.join(gram) for gram in x]))\n",
    "\n",
    "# Use only bigrams for TF-IDF vectorization\n",
    "df['combined_text'] = df['bigrams_text']\n",
    "\n",
    "# Split the dataset\n",
    "X_train_bi, X_test_bi, y_train_bi, y_test_bi = train_test_split(df['combined_text'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf_bi = tfidf_vectorizer.fit_transform(X_train_bi)\n",
    "X_test_tfidf_bi = tfidf_vectorizer.transform(X_test_bi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ccd1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate uni-bigrams\n",
    "df['uni_bigrams'] = df['cleaned_text'].apply(lambda x: list(ngrams(x, 2)))\n",
    "\n",
    "# Convert uni-bigrams back to text\n",
    "df['uni_bigrams_text'] = df['uni_bigrams'].apply(lambda x: ' '.join([' '.join(gram) for gram in x]))\n",
    "\n",
    "# Combine unigrams and uni-bigrams for TF-IDF vectorization\n",
    "df['combined_text'] = df['cleaned_text'].apply(lambda x: ' '.join(x)) + ' ' + df['uni_bigrams_text']\n",
    "\n",
    "# Split the dataset\n",
    "X_train_uni, X_test_uni, y_train_uni, y_test_uni = train_test_split(df['combined_text'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf_uni = tfidf_vectorizer.fit_transform(X_train_uni)\n",
    "X_test_tfidf_uni = tfidf_vectorizer.transform(X_test_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get Misclassified Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5388ffaa66cd4033"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_wrong_reviews(model, x_test, test_labels, name):\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "    # Identify misclassifications\n",
    "    misclassified_indices = [i for i in range(len(test_labels)) if test_labels.iloc[i] != y_pred[i]]\n",
    "\n",
    "    # Retrieve misclassified entries\n",
    "    misclassified_entries = df.iloc[misclassified_indices].copy()\n",
    "\n",
    "    # Add predicted labels to the DataFrame\n",
    "    misclassified_entries['Predicted Label'] = y_pred[misclassified_indices]\n",
    "\n",
    "    # Save DataFrame with only misclassified entries as csv\n",
    "    file_path = f\"/Users/blankajarmoszko/PycharmProjects/thesis/models/missclassified_data/{name}.csv\"\n",
    "    misclassified_entries.to_csv(file_path, index=False)\n",
    "    print(\"Done\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "196c274873dbaba8"
  },
  {
   "cell_type": "markdown",
   "id": "cf3f0f62",
   "metadata": {},
   "source": [
    "## Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c35f410",
   "metadata": {},
   "source": [
    "### Naive Bayes w/ BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e651b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "naive_bayes_model_bow = MultinomialNB()\n",
    "naive_bayes_model_bow.fit(X_train_vectorized_bow, train_labels)\n",
    "\n",
    "print(f\"Naive Bayes w/ BOW: \")\n",
    "# Make predictions on the test set\n",
    "test_predictions = naive_bayes_model_bow.predict(X_test_vectorized_bow)\n",
    "# Evaluate the model\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(classification_report(test_labels, test_predictions))\n",
    "\n",
    "# Make predictions on the train set\n",
    "train_predictions = naive_bayes_model_bow.predict(X_train_vectorized_bow)\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(classification_report(train_labels, train_predictions))\n",
    "\n",
    "# Print confusion matrices for train and test\n",
    "print(\"\\nConfusion Matrix for Train Set:\")\n",
    "print(confusion_matrix(train_labels, train_predictions))\n",
    "\n",
    "print(\"\\nConfusion Matrix for Test Set:\")\n",
    "print(confusion_matrix(test_labels, test_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4dd492",
   "metadata": {},
   "source": [
    "### Naive Bayes with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c12df3344f32230d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d26a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "naive_bayes_model_tf = MultinomialNB(alpha=0.01)\n",
    "naive_bayes_model_tf.fit(X_train_tfidf, train_labels)\n",
    "print(f\"Naive Bayes w/ tfidf: \")\n",
    "# Make predictions on the test set\n",
    "test_predictions = naive_bayes_model_tf.predict(X_test_tfidf)\n",
    "# Evaluate the model\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(classification_report(test_labels, test_predictions))\n",
    "\n",
    "# Make predictions on the train set\n",
    "train_predictions = naive_bayes_model_tf.predict(X_train_tfidf)\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(classification_report(train_labels, train_predictions))\n",
    "\n",
    "# Print confusion matrices for train and test\n",
    "print(\"\\nConfusion Matrix for Train Set:\")\n",
    "print(confusion_matrix(train_labels, train_predictions))\n",
    "\n",
    "print(\"\\nConfusion Matrix for Test Set:\")\n",
    "print(confusion_matrix(test_labels, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2d3ca6544e4c4c07"
  },
  {
   "cell_type": "markdown",
   "id": "b267797330f3a36e",
   "metadata": {},
   "source": [
    "### Naive Bayes with tfidf and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e66cddacff5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "naive_bayes_model_tf_bi = MultinomialNB()\n",
    "naive_bayes_model_tf_bi.fit(X_train_tfidf_bi, y_train_bi)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = naive_bayes_model_tf_bi.predict(X_test_tfidf_bi)\n",
    "# Evaluate the model\n",
    "test_accuracy = accuracy_score(y_test_bi, test_predictions)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(classification_report(y_test_bi, test_predictions))\n",
    "\n",
    "# Make predictions on the train set\n",
    "train_predictions = naive_bayes_model_tf_bi.predict(X_train_tfidf_bi)\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train_bi, train_predictions)\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(classification_report(y_train_bi, train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f586a5b2616fcc",
   "metadata": {},
   "source": [
    "### Naive Bayes with tfidf and uni-bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9ad619e825e4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "naive_bayes_model_tf_uni = MultinomialNB()\n",
    "naive_bayes_model_tf_uni.fit(X_train_tfidf_uni, y_train_uni)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = naive_bayes_model_tf_uni.predict(X_test_tfidf_uni)\n",
    "# Evaluate the model\n",
    "test_accuracy = accuracy_score(y_test_uni, test_predictions)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(classification_report(y_test_uni, test_predictions))\n",
    "\n",
    "# Make predictions on the train set\n",
    "train_predictions = naive_bayes_model_tf_uni.predict(X_train_tfidf_uni)\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train_uni, train_predictions)\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(classification_report(y_train_uni, train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b53ca2e5adb343f",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a753f933aa36f70",
   "metadata": {},
   "source": [
    "## SVM w/ bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58993e8bb87c7598",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X_train_vectorized_bow,train_labels)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(X_test_vectorized_bow)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, test_labels)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687bf6ff1b09bc70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5df538211fff02e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78751df791c4c530",
   "metadata": {},
   "source": [
    "## SVM w/ tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fdd69d32b03d66",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X_train_tfidf,train_labels)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(X_test_tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, test_labels)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f70e30108e79074",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obtain the confusion matrix\n",
    "cm = confusion_matrix(test_labels, predictions_SVM)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix - SVM Classifier\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a06196a861d282a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671c38c0bc2d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_SVM = SVM.predict(X_train_tfidf)\n",
    "print(\"TRAIN SVM Accuracy Score -> \",accuracy_score(train_predictions_SVM, train_labels)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5fd43eed7d53be",
   "metadata": {},
   "source": [
    "### SVM with random search hyperparam tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f8b44bd0fa6492",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Define the parameter distributions\n",
    "param_distributions = {\n",
    "    'C': uniform(loc=0.1, scale=100),  # Regularization parameter\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  # Kernel type\n",
    "    'degree': [2, 3, 4],  # Degree of the polynomial kernel (if polynomial)\n",
    "    'gamma': ['scale', 'auto']  # Kernel coefficient (for 'rbf', 'poly', and 'sigmoid')\n",
    "}\n",
    "\n",
    "# Create the SVM classifier\n",
    "svm_classifier = svm.SVC()\n",
    "\n",
    "# Perform randomized search with cross-validation\n",
    "random_search = RandomizedSearchCV(svm_classifier, param_distributions, n_iter=20, cv=5, scoring='accuracy', random_state=42)\n",
    "random_search.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Make predictions using the best model\n",
    "best_model = random_search.best_estimator_\n",
    "predictions = best_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(\"Accuracy Score:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f812581",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eda50c",
   "metadata": {},
   "source": [
    "### Logistic Regression w/ BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d335bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression classifier\n",
    "logistic_regression_model_bow = LogisticRegression()\n",
    "logistic_regression_model_bow.fit(X_train_vectorized_bow, train_labels)\n",
    "\n",
    "print(\"Logistic Regression w/ BOW\")\n",
    "# Make predictions on the test set\n",
    "test_predictions = logistic_regression_model_bow.predict(X_test_vectorized_bow)\n",
    "# Evaluate the model\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(classification_report(test_labels, test_predictions))\n",
    "\n",
    "# Make predictions on the train set\n",
    "train_predictions = logistic_regression_model_bow.predict(X_train_vectorized_bow)\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(classification_report(train_labels, train_predictions))\n",
    "\n",
    "# Print confusion matrices for train and test\n",
    "print(\"\\nConfusion Matrix for Train Set:\")\n",
    "print(confusion_matrix(train_labels, train_predictions))\n",
    "\n",
    "print(\"\\nConfusion Matrix for Test Set:\")\n",
    "print(confusion_matrix(test_labels, test_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52630ed",
   "metadata": {},
   "source": [
    "### Logistic Regression w/ tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a650a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression classifier\n",
    "logistic_regression_model_tfidf = LogisticRegression()\n",
    "logistic_regression_model_tfidf.fit(X_train_tfidf, train_labels)\n",
    "print(\"Logistic Regression w/ tfidf\")\n",
    "# Make predictions on the test set\n",
    "test_predictions = logistic_regression_model_tfidf.predict(X_test_tfidf)\n",
    "# Evaluate the model\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(classification_report(test_labels, test_predictions))\n",
    "\n",
    "# Make predictions on the train set\n",
    "train_predictions = logistic_regression_model_tfidf.predict(X_train_tfidf)\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(classification_report(train_labels, train_predictions))\n",
    "\n",
    "# Print confusion matrices for train and test\n",
    "print(\"\\nConfusion Matrix for Train Set:\")\n",
    "print(confusion_matrix(train_labels, train_predictions))\n",
    "\n",
    "print(\"\\nConfusion Matrix for Test Set:\")\n",
    "print(confusion_matrix(test_labels, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142a86761c78dcdb",
   "metadata": {},
   "source": [
    "### Tunning Logistic Regression with TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7a177a2ae8f114f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05c6eef679eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the Logistic Regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'C': [0.1, 1],  # Regularization parameter\n",
    "    'penalty': ['l1', 'l2'],  # Penalty norm\n",
    "    'solver': ['liblinear', 'saga']  # Optimization algorithm\n",
    "}\n",
    "\n",
    "# Perform Grid Search cross-validation\n",
    "grid_search = GridSearchCV(estimator=logistic_regression_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose =2)\n",
    "grid_search.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_report(test_labels, predictions))\n",
    "\n",
    "# Make predictions on the train and test set using the best model\n",
    "train_predictions = best_model.predict(X_train_tfidf)\n",
    "test_predictions = best_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate train and test accuracy\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "# Print train and test accuracy for the best model\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "test_predictions = best_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Best Parameters: {'C': 1, 'penalty': 'l2', 'solver': 'saga'}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d185a88e70b0c610"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_params = {'C': 1, 'penalty': 'l2', 'solver': 'saga'}\n",
    "# Train a Logistic Regression classifier\n",
    "logistic_regression_model_tfidf = LogisticRegression(best_params)\n",
    "logistic_regression_model_tfidf.fit(X_train_tfidf, train_labels)\n",
    "print(\"Tunned Logistic Regression w/ tfidf\")\n",
    "print(\"Best params:\", best_params)\n",
    "# Make predictions on the test set\n",
    "test_predictions = logistic_regression_model_tfidf.predict(X_test_tfidf)\n",
    "# Evaluate the model\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(classification_report(test_labels, test_predictions))\n",
    "\n",
    "# Make predictions on the train set\n",
    "train_predictions = logistic_regression_model_tfidf.predict(X_train_tfidf)\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(classification_report(train_labels, train_predictions))\n",
    "\n",
    "# Print confusion matrices for train and test\n",
    "print(\"\\nConfusion Matrix for Train Set:\")\n",
    "print(confusion_matrix(train_labels, train_predictions))\n",
    "\n",
    "print(\"\\nConfusion Matrix for Test Set:\")\n",
    "print(confusion_matrix(test_labels, test_predictions))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db7e66fc2ef1316a"
  },
  {
   "cell_type": "markdown",
   "id": "4485fd92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T20:04:06.817111Z",
     "start_time": "2024-04-15T20:04:06.624017Z"
    }
   },
   "source": [
    "### Logistic Regression with TFIDF and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d92a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model (e.g., logistic regression)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf_bi, y_train_bi)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = model.predict(X_test_tfidf_bi)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = accuracy_score(y_test_bi, test_predictions)\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(classification_report(y_test_bi, test_predictions))\n",
    "\n",
    "# Make predictions on the train set\n",
    "train_predictions = model.predict(X_train_tfidf_bi)\n",
    "\n",
    "# Evaluate the model on the train set\n",
    "train_accuracy = accuracy_score(y_train_bi, train_predictions)\n",
    "print(\"Train Set:\")\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(classification_report(y_train_bi, train_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8f8d2d",
   "metadata": {},
   "source": [
    "### Logistic Regression with TFIDF and uni-bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c75da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model (e.g., logistic regression)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf_uni, y_train_uni)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = model.predict(X_test_tfidf_uni)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = accuracy_score(y_test_uni, test_predictions)\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(classification_report(y_test_uni, test_predictions))\n",
    "\n",
    "# Make predictions on the train set\n",
    "train_predictions = model.predict(X_train_tfidf_uni)\n",
    "\n",
    "# Evaluate the model on the train set\n",
    "train_accuracy = accuracy_score(y_train_uni, train_predictions)\n",
    "print(\"Train Set:\")\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(classification_report(y_train_uni, train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e996b185",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f8ed268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T02:06:47.023077Z",
     "start_time": "2024-04-16T02:06:46.689910Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590f86f5",
   "metadata": {},
   "source": [
    "### Random Forrest with bofw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e42834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Random Forest model\n",
    "random_forest_model_bofw = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "random_forest_model_bofw.fit(X_train_vectorized_bow, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = random_forest_model_bofw.predict(X_test_vectorized_bow)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(classification_report(test_labels, test_predictions))\n",
    "\n",
    "# Make predictions on the train set\n",
    "train_predictions = random_forest_model_bofw.predict(X_train_vectorized_bow)\n",
    "\n",
    "# Evaluate the model on the train set\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "print(\"Train Set:\")\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(classification_report(train_labels, train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4069e7",
   "metadata": {},
   "source": [
    "### Random Forrest witb tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13fed21b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T23:44:17.829975Z",
     "start_time": "2024-04-16T23:01:33.541458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest tfidf\n",
      "\n",
      "Test Set:\n",
      "Test Accuracy: 0.5707845873135129\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65      2767\n",
      "           1       0.48      0.23      0.31      2941\n",
      "           2       0.55      0.79      0.65      3609\n",
      "\n",
      "    accuracy                           0.57      9317\n",
      "   macro avg       0.56      0.56      0.54      9317\n",
      "weighted avg       0.56      0.57      0.54      9317\n",
      "Train Set:\n",
      "Train Accuracy: 0.9975582268970699\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     11034\n",
      "           1       1.00      1.00      1.00     11868\n",
      "           2       1.00      1.00      1.00     14366\n",
      "\n",
      "    accuracy                           1.00     37268\n",
      "   macro avg       1.00      1.00      1.00     37268\n",
      "weighted avg       1.00      1.00      1.00     37268\n",
      "\n",
      "\n",
      "Confusion Matrix for Train Set:\n",
      "[[10995    33     6]\n",
      " [   13 11840    15]\n",
      " [    4    20 14342]]\n",
      "\n",
      "Confusion Matrix for Test Set:\n",
      "[[1795  292  680]\n",
      " [ 619  682 1640]\n",
      " [ 333  435 2841]]\n"
     ]
    }
   ],
   "source": [
    "# Build the Random Forest model\n",
    "random_forest_model_tfidf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "random_forest_model_tfidf.fit(X_train_tfidf, train_labels)\n",
    "print(\"Random Forest tfidf\")\n",
    "# Make predictions on the train set\n",
    "test_predictions = random_forest_model_tfidf.predict(X_test_tfidf)\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(classification_report(test_labels, test_predictions))\n",
    "\n",
    "# Make predictions on the train set\n",
    "train_predictions = random_forest_model_tfidf.predict(X_train_tfidf)\n",
    "\n",
    "# Evaluate the model on the train set\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "print(\"Train Set:\")\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(classification_report(train_labels, train_predictions))\n",
    "\n",
    "# Print confusion matrices for train and test\n",
    "print(\"\\nConfusion Matrix for Train Set:\")\n",
    "print(confusion_matrix(train_labels, train_predictions))\n",
    "\n",
    "print(\"\\nConfusion Matrix for Test Set:\")\n",
    "print(confusion_matrix(test_labels, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feff84d0de54a98f",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-15T20:05:39.657766Z"
    }
   },
   "source": [
    "### Tunning Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2776fda1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T21:32:01.872083Z",
     "start_time": "2024-04-16T03:29:32.467481Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 19\u001B[0m\n\u001B[1;32m     16\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mrandom_forest, param_grid\u001B[38;5;241m=\u001B[39mparam_grid, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_tfidf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Get the best parameters\u001B[39;00m\n\u001B[1;32m     22\u001B[0m best_params \u001B[38;5;241m=\u001B[39m grid_search\u001B[38;5;241m.\u001B[39mbest_params_\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1472\u001B[0m     )\n\u001B[1;32m   1473\u001B[0m ):\n\u001B[0;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, **params)\u001B[0m\n\u001B[1;32m    964\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    965\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    966\u001B[0m     )\n\u001B[1;32m    968\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 970\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    972\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    973\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    974\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1527\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1525\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1526\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1527\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:916\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    908\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    909\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    910\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    911\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    912\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    913\u001B[0m         )\n\u001B[1;32m    914\u001B[0m     )\n\u001B[0;32m--> 916\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    918\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    920\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    922\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    924\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    925\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    927\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    928\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    929\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    930\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    931\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    932\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    934\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    935\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    936\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    937\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    938\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    939\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     66\u001B[0m )\n\u001B[0;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/joblib/parallel.py:1863\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1861\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[1;32m   1862\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 1863\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1865\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[1;32m   1866\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[1;32m   1867\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[1;32m   1868\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[1;32m   1869\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[1;32m   1870\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/joblib/parallel.py:1792\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1790\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1791\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 1792\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1793\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1794\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:129\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    127\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[0;32m--> 129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:895\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    893\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m    894\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 895\u001B[0m         \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    897\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m    898\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[1;32m    899\u001B[0m     fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1472\u001B[0m     )\n\u001B[1;32m   1473\u001B[0m ):\n\u001B[0;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:489\u001B[0m, in \u001B[0;36mBaseForest.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    478\u001B[0m trees \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    479\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_estimator(append\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39mrandom_state)\n\u001B[1;32m    480\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_more_estimators)\n\u001B[1;32m    481\u001B[0m ]\n\u001B[1;32m    483\u001B[0m \u001B[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001B[39;00m\n\u001B[1;32m    484\u001B[0m \u001B[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001B[39;00m\n\u001B[1;32m    485\u001B[0m \u001B[38;5;66;03m# making threading more efficient than multiprocessing in\u001B[39;00m\n\u001B[1;32m    486\u001B[0m \u001B[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001B[39;00m\n\u001B[1;32m    487\u001B[0m \u001B[38;5;66;03m# parallel_backend contexts set at a higher level,\u001B[39;00m\n\u001B[1;32m    488\u001B[0m \u001B[38;5;66;03m# since correctness does not rely on using threads.\u001B[39;00m\n\u001B[0;32m--> 489\u001B[0m trees \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprefer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mthreads\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_parallel_build_trees\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    495\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbootstrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrees\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    505\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    506\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    507\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrees\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    508\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    510\u001B[0m \u001B[38;5;66;03m# Collect newly grown trees\u001B[39;00m\n\u001B[1;32m    511\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_\u001B[38;5;241m.\u001B[39mextend(trees)\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     66\u001B[0m )\n\u001B[0;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/joblib/parallel.py:1863\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1861\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[1;32m   1862\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 1863\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1865\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[1;32m   1866\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[1;32m   1867\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[1;32m   1868\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[1;32m   1869\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[1;32m   1870\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/joblib/parallel.py:1792\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1790\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1791\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 1792\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1793\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1794\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:129\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    127\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[0;32m--> 129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:192\u001B[0m, in \u001B[0;36m_parallel_build_trees\u001B[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001B[0m\n\u001B[1;32m    189\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m class_weight \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbalanced_subsample\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    190\u001B[0m         curr_sample_weight \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m compute_sample_weight(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbalanced\u001B[39m\u001B[38;5;124m\"\u001B[39m, y, indices\u001B[38;5;241m=\u001B[39mindices)\n\u001B[0;32m--> 192\u001B[0m     \u001B[43mtree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    193\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    194\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    195\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcurr_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    196\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    197\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    200\u001B[0m     tree\u001B[38;5;241m.\u001B[39m_fit(\n\u001B[1;32m    201\u001B[0m         X,\n\u001B[1;32m    202\u001B[0m         y,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    205\u001B[0m         missing_values_in_feature_mask\u001B[38;5;241m=\u001B[39mmissing_values_in_feature_mask,\n\u001B[1;32m    206\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/thesis/venv/lib/python3.10/site-packages/sklearn/tree/_classes.py:472\u001B[0m, in \u001B[0;36mBaseDecisionTree._fit\u001B[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001B[0m\n\u001B[1;32m    461\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    462\u001B[0m     builder \u001B[38;5;241m=\u001B[39m BestFirstTreeBuilder(\n\u001B[1;32m    463\u001B[0m         splitter,\n\u001B[1;32m    464\u001B[0m         min_samples_split,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    469\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_impurity_decrease,\n\u001B[1;32m    470\u001B[0m     )\n\u001B[0;32m--> 472\u001B[0m \u001B[43mbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtree_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    474\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m is_classifier(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    475\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define the parameter grid to search\n",
    "# Best Parameters: {'n_estimators': 75, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': None}\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Train the model\n",
    "grid_search.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Build the Random Forest model with the best parameters\n",
    "random_forest_model_tfidf = RandomForestClassifier(**best_params, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "random_forest_model_tfidf.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = random_forest_model_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(classification_report(test_labels, test_predictions))\n",
    "\n",
    "# Make predictions on the train set\n",
    "train_predictions = random_forest_model_tfidf.predict(X_train_tfidf)\n",
    "\n",
    "# Evaluate the model on the train set\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "print(\"Train Set:\")\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(classification_report(train_labels, train_predictions))\n",
    "\n",
    "# Best Parameters: {'n_estimators': 75, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Random Forest tfidf\n",
      "Best Params:  {'n_estimators': 75, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': None}\n",
      "\n",
      "Test Set:\n",
      "Test Accuracy: 0.5699259418267683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.54      0.64      2767\n",
      "           1       0.59      0.15      0.24      2941\n",
      "           2       0.51      0.93      0.66      3609\n",
      "\n",
      "    accuracy                           0.57      9317\n",
      "   macro avg       0.63      0.54      0.51      9317\n",
      "weighted avg       0.62      0.57      0.52      9317\n",
      "Train Set:\n",
      "Train Accuracy: 0.6676236986154341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.62      0.74     11034\n",
      "           1       0.88      0.33      0.47     11868\n",
      "           2       0.56      0.99      0.71     14366\n",
      "\n",
      "    accuracy                           0.67     37268\n",
      "   macro avg       0.78      0.64      0.64     37268\n",
      "weighted avg       0.76      0.67      0.64     37268\n",
      "\n",
      "\n",
      "Confusion Matrix for Train Set:\n",
      "[[ 6864   420  3750]\n",
      " [  638  3866  7364]\n",
      " [   88   127 14151]]\n",
      "\n",
      "Confusion Matrix for Test Set:\n",
      "[[1489  175 1103]\n",
      " [ 308  452 2181]\n",
      " [ 104  136 3369]]\n"
     ]
    }
   ],
   "source": [
    "# Build the Tuned Random Forest model\n",
    "best_params = {'n_estimators': 75, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': None}\n",
    "random_forest_model_tfidf = RandomForestClassifier(n_estimators=75,min_samples_split=10, min_samples_leaf=4, max_features='sqrt', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "random_forest_model_tfidf.fit(X_train_tfidf, train_labels)\n",
    "print(\"Tuned Random Forest tfidf\")\n",
    "print(\"Best Params: \", best_params)\n",
    "# Make predictions on the train set\n",
    "test_predictions = random_forest_model_tfidf.predict(X_test_tfidf)\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(classification_report(test_labels, test_predictions))\n",
    "\n",
    "# Make predictions on the train set\n",
    "train_predictions = random_forest_model_tfidf.predict(X_train_tfidf)\n",
    "\n",
    "# Evaluate the model on the train set\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "print(\"Train Set:\")\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(classification_report(train_labels, train_predictions))\n",
    "\n",
    "# Print confusion matrices for train and test\n",
    "print(\"\\nConfusion Matrix for Train Set:\")\n",
    "print(confusion_matrix(train_labels, train_predictions))\n",
    "\n",
    "print(\"\\nConfusion Matrix for Test Set:\")\n",
    "print(confusion_matrix(test_labels, test_predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T03:22:02.303993Z",
     "start_time": "2024-04-16T03:21:24.306052Z"
    }
   },
   "id": "b40607859792682f"
  },
  {
   "cell_type": "markdown",
   "id": "25b70d6d2c65efd0",
   "metadata": {},
   "source": [
    "2### ADA Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab3f6683d9f56ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Define a shallow decision tree as the base estimator\n",
    "base_estimator = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "# Reduce the number of estimators to make training faster\n",
    "classifier = AdaBoostClassifier( base_estimator, n_estimators=50)\n",
    "\n",
    "# Fit the classifier\n",
    "classifier.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Predictions on training set\n",
    "train_preds = classifier.predict(X_train_tfidf)\n",
    "\n",
    "# Predictions on test set\n",
    "test_preds = classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Classification report and confusion matrix for training set\n",
    "print(\"Training Set:\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(train_labels, train_preds))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(train_labels, train_preds))\n",
    "\n",
    "# Classification report and confusion matrix for test set\n",
    "print(\"\\nTest Set:\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, test_preds))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_labels, test_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba503c442c607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the base estimator\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "\n",
    "# Define the AdaBoostClassifier with the base estimator\n",
    "classifier = AdaBoostClassifier(estimator=base_estimator)\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [20, 30, 50],  # Try different numbers of estimators\n",
    "    'estimator__max_depth': [1, 2, 3],  # Try different depths for the decision trees\n",
    "    'learning_rate': [0.1, 0.5, 1.0]  # Try different learning rates\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best estimator\n",
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Fit the best classifier to the training data\n",
    "best_classifier.fit(X_train_tfidf, train_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69aad2700b971b",
   "metadata": {},
   "source": [
    "### Tunned ADABoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8854fcbbdb45decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a shallow decision tree as the base estimator\n",
    "base_estimator = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# Reduce the number of estimators to make training faster\n",
    "classifier = AdaBoostClassifier( base_estimator, n_estimators=50, learning_rate= 0.5)\n",
    "\n",
    "# Fit the classifier\n",
    "classifier.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Predictions on training set\n",
    "train_preds = classifier.predict(X_train_tfidf)\n",
    "\n",
    "# Predictions on test set\n",
    "test_preds = classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Classification report and confusion matrix for training set\n",
    "print(\"Training Set:\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(train_labels, train_preds))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(train_labels, train_preds))\n",
    "\n",
    "# Classification report and confusion matrix for test set\n",
    "print(\"\\nTest Set:\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, test_preds))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_labels, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8fa655ffcc67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the base estimator\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "\n",
    "# Define the AdaBoostClassifier with the base estimator\n",
    "classifier = AdaBoostClassifier(estimator=base_estimator, learning_rate=0.5)\n",
    "# Best Parameters: {'estimator__max_depth': 3, 'learning_rate': 0.5, 'n_estimators': 50}\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [40,50,100],  # Try different numbers of estimators\n",
    "    'estimator__max_depth': [3,5,6]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best estimator\n",
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Fit the best classifier to the training data\n",
    "best_classifier.fit(X_train_tfidf, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea10b32a8691f13",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2317239ab54356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the KNN classifier with default parameters\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Fit the KNN classifier to the training data\n",
    "knn_classifier.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Predictions on training set\n",
    "train_preds = knn_classifier.predict(X_train_tfidf)\n",
    "\n",
    "# Predictions on test set\n",
    "test_preds = knn_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Classification report and confusion matrix for training set\n",
    "print(\"Training Set:\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(train_labels, train_preds))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(train_labels, train_preds))\n",
    "\n",
    "# Classification report and confusion matrix for test set\n",
    "print(\"\\nTest Set:\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, test_preds))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_labels, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0329b9a6ac7e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tunning KNN\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# weights, distance params\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11]  # Adjust the range as needed\n",
    "}\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=knn_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Best parameter found during grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Refit the best model to the entire training set\n",
    "best_knn_classifier = grid_search.best_estimator_\n",
    "best_knn_classifier.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Predictions on training set\n",
    "train_preds = best_knn_classifier.predict(X_train_tfidf)\n",
    "\n",
    "# Predictions on test set\n",
    "test_preds = best_knn_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Classification report and confusion matrix for training set\n",
    "print(\"Training Set:\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(train_labels, train_preds))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(train_labels, train_preds))\n",
    "\n",
    "# Classification report and confusion matrix for test set\n",
    "print(\"\\nTest Set:\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, test_preds))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_labels, test_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d2259e7cdccbea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c8c83514c2bd79f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
